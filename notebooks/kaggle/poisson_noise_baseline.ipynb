{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8129297,"sourceType":"datasetVersion","datasetId":4804759}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf \nimport numpy as np\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:50:30.087305Z","iopub.execute_input":"2024-04-24T06:50:30.087697Z","iopub.status.idle":"2024-04-24T06:50:30.093131Z","shell.execute_reply.started":"2024-04-24T06:50:30.087664Z","shell.execute_reply":"2024-04-24T06:50:30.091911Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pydicom\n\nRESIZE_DIM = 256\n\ndef read_dcm(img_path):\n    img_dicom = pydicom.dcmread(img_path)\n    # convert to numpy array\n    # Check the PhotometricInterpretation metadata\n    if img_dicom.PhotometricInterpretation == 'MONOCHROME1':\n        image = np.invert(img_dicom.pixel_array)\n    else:\n        image = img_dicom.pixel_array\n\n    # Rescale the pixel values to [0, 255]\n    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n\n    # Resize the image to desired size\n    return cv2.resize(image, (RESIZE_DIM, RESIZE_DIM))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:50:30.100820Z","iopub.execute_input":"2024-04-24T06:50:30.101256Z","iopub.status.idle":"2024-04-24T06:50:30.110010Z","shell.execute_reply.started":"2024-04-24T06:50:30.101213Z","shell.execute_reply":"2024-04-24T06:50:30.109110Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from skimage.util import random_noise\nfrom enum import Enum\n\nclass NoiseType(Enum):\n    GAUSSIAN = 1\n    POISSON = 2\n    SALT_AND_PEPPER = 3\n    SPECKLE = 4\n\n\"\"\"\n This class defines the noise configuration to be applied to the CT scan dataset.\n\"\"\"\nclass NoiseConfiguration:\n    def __init__(self, noise_types, noise_levels):\n        \"\"\"\n        Initialize the noise configuration.\n\n        Args:\n            noise_types (list): A list of noise types to apply. Supported types are NoiseType enums.\n            noise_levels (list): A list of noise levels to apply, corresponding to the noise types.\n        \"\"\"\n        self.noise_types = noise_types\n        self.noise_levels = noise_levels\n\n\"\"\"\nThis class simulates different types of noise on CT scan images.\n\"\"\"\nclass NoiseSimulator:\n    @staticmethod\n    def apply_gaussian_noise(image, sigma):\n        \"\"\"\n        Apply Gaussian noise to the input image.\n\n        Gaussian noise is a common type of noise that can be observed in medical imaging due to various factors, such as electronic noise in the imaging device or thermal noise. This type of noise is characterized by a normal distribution of pixel values around the original pixel value.\n\n        Args:\n            image (numpy.ndarray): The input image to be transformed.\n            noise_level (float): The standard deviation of the Gaussian noise to be applied.\n\n        Returns:\n            numpy.ndarray: The image with Gaussian noise applied.\n        \"\"\"\n        noisy_image = random_noise(image, mode=\"gaussian\", var=sigma**2)\n\n        return noisy_image\n\n    @staticmethod\n    def apply_poisson_noise(image):\n        \"\"\"\n        Apply Poisson noise to the input image.\n\n        Poisson noise is another type of noise that is common in medical imaging, especially in low-light conditions or when the signal-to-noise ratio is low.\n        This type of noise is characterized by a Poisson distribution of pixel values, where the variance of the noise is proportional to the original pixel value.\n\n        Args:\n            image (numpy.ndarray): The input image to be transformed.\n\n        Returns:\n            numpy.ndarray: The image with Poisson noise applied.\n        \"\"\"\n        \n        return random_noise(image, mode=\"poisson\", clip=True)\n\n\n\n    @staticmethod\n    def apply_salt_and_pepper_noise(image, noise_pct):\n        \"\"\"\n        Apply salt-and-pepper noise to the input image.\n\n        Salt-and-pepper noise is a type of noise that can be observed in medical imaging due to sensor errors or bit errors during data transmission. \n        This type of noise is characterized by randomly occurring white and black pixels, which can be interpreted as \"salt\" (white) and \"pepper\" (black) pixels.\n\n        Args:\n            image (numpy.ndarray): The input image to be transformed.\n            noise_pct (float): The proportion of pixels to apply Poisson noise to (0-1).\n\n        Returns:\n            numpy.ndarray: The image with salt-and-pepper noise applied.\n        \"\"\"\n\n        return random_noise(image, mode=\"s&p\", amount=noise_pct)\n\n\n    @staticmethod\n    def apply_speckle_noise(image, noise_level):\n        \"\"\"\n        Apply speckle noise to the input image.\n\n        Speckle noise is a type of multiplicative noise that is common in ultrasound imaging. This type of noise is characterized by a granular pattern that can be observed in the image due to interference between the transmitted and reflected signals.\n\n        Args:\n            image (numpy.ndarray): The input image to be transformed.\n            noise_level (float): The variance of the speckle noise to be applied.\n\n        Returns:\n            numpy.ndarray: The image with speckle noise applied.\n        \"\"\"\n\n        return random_noise(image, mode=\"speckle\", var=noise_level**2)\n    \n\n    @staticmethod\n    def apply_noise(image: np.ndarray, noise_config: NoiseConfiguration):\n        \"\"\"\n        Apply the specified noise configurations to the input image.\n\n        Args:\n            image (numpy.ndarray): The input image to be transformed.\n            noise_config (NoiseConfiguration): The noise configuration object that defines the noise types and levels to be applied.\n\n        Returns:\n            numpy.ndarray: The image with the specified noise applied.\n        \"\"\"\n        noisy_image = image.copy()\n        for noise_type, noise_level in zip(noise_config.noise_types, noise_config.noise_levels):\n            if noise_type == NoiseType.GAUSSIAN:\n                noisy_image = NoiseSimulator.apply_gaussian_noise(noisy_image, noise_level)\n            elif noise_type == NoiseType.POISSON:\n                noisy_image = NoiseSimulator.apply_poisson_noise(noisy_image)\n            elif noise_type == NoiseType.SALT_AND_PEPPER:\n                noisy_image = NoiseSimulator.apply_salt_and_pepper_noise(noisy_image, noise_level)\n            elif noise_type == NoiseType.SPECKLE:\n                noisy_image = NoiseSimulator.apply_speckle_noise(noisy_image, noise_level)\n            else:\n                raise ValueError(f\"Unsupported noise type: {noise_type}\")\n            \n        return noisy_image","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:50:30.111165Z","iopub.execute_input":"2024-04-24T06:50:30.111458Z","iopub.status.idle":"2024-04-24T06:50:30.126453Z","shell.execute_reply.started":"2024-04-24T06:50:30.111433Z","shell.execute_reply":"2024-04-24T06:50:30.125557Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from skimage.transform import iradon, radon\n\ndef get_noisy_image(image):\n    subsample = 8\n    theta = np.linspace(0., 180., max(image.shape)//subsample, endpoint=False)\n    sinogram = radon(image, theta=theta)\n    simulation_config = NoiseConfiguration([NoiseType.POISSON], [])\n    noisy_sinogram = NoiseSimulator.apply_noise(sinogram, simulation_config)\n    return iradon(noisy_sinogram, theta=theta, filter_name='ramp')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:50:30.128312Z","iopub.execute_input":"2024-04-24T06:50:30.128600Z","iopub.status.idle":"2024-04-24T06:50:30.142048Z","shell.execute_reply.started":"2024-04-24T06:50:30.128577Z","shell.execute_reply":"2024-04-24T06:50:30.141125Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def get_train_and_test_data():\n  print(\"Getting train and test data\")\n  df=pd.read_csv(\"/kaggle/input/rsna-bme548/RSNA_BME548/data.csv\")\n\n  files=glob.glob(\"/kaggle/input/rsna-bme548/RSNA_BME548/images/*.dcm\")\n\n  label=[]\n  img_array=[]\n  for i in files:\n    filename = os.path.basename(i)\n    img=read_dcm(i)\n    noisy_img = get_noisy_image(img)\n    img_array.append(np.array(noisy_img))\n    # Get value of column \"any\" for the row with filename as index\n    label.append(df.loc[df['filename'] == filename]['any'].values[0])\n\n  x = np.array(img_array)\n  x = x/255\n  y = np.array(label)\n\n  x = np.expand_dims(x,3)\n  X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.15, random_state = 0)\n  \n  return X_train, X_test, y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:50:30.142974Z","iopub.execute_input":"2024-04-24T06:50:30.143229Z","iopub.status.idle":"2024-04-24T06:50:30.156066Z","shell.execute_reply.started":"2024-04-24T06:50:30.143208Z","shell.execute_reply":"2024-04-24T06:50:30.155170Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class Block(tf.keras.Model):\n    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n        super(Block, self).__init__()\n        self.filters =filters\n        self.kernel_size = kernel_size\n        self.repetitions = repetitions\n        \n        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\n        for i in range(self.repetitions):\n            \n            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\n            vars(self)[f'conv2D_{i}'] = tf.keras.layers.Conv2D(self.filters,self.kernel_size,activation='relu',padding=\"same\")\n        \n        # Define the max pool layer that will be added after the Conv2D blocks\n        self.max_pool = tf.keras.layers.MaxPooling2D(pool_size, strides=strides)\n  \n    def call(self, inputs):\n        # access the class's conv2D_0 layer\n        conv2D_0 = vars(self)['conv2D_0']\n        \n        # Connect the conv2D_0 layer to inputs\n        x = conv2D_0(inputs)\n\n        # for the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\n        for i in range(1,self.repetitions):\n            # access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\n            conv2D_i = vars(self)[f'conv2D_{i}']\n            \n            # Use the conv2D_i and connect it to the previous layer\n            x = conv2D_i(x)\n\n        # Finally, add the max_pool layer\n        max_pool = self.max_pool(x)\n        \n        return max_pool","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:50:30.185750Z","iopub.execute_input":"2024-04-24T06:50:30.186600Z","iopub.status.idle":"2024-04-24T06:50:30.194661Z","shell.execute_reply.started":"2024-04-24T06:50:30.186570Z","shell.execute_reply":"2024-04-24T06:50:30.193791Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class MyVGG(tf.keras.Model):\n\n    def __init__(self, num_classes):\n        super(MyVGG, self).__init__()\n\n        # Creating blocks of VGG with the following \n        # (filters, kernel_size, repetitions) configurations\n        self.block_a = Block(filters=64, kernel_size=3, repetitions=2)\n        self.block_b = Block(filters=128, kernel_size=3, repetitions=2)\n        self.block_c = Block(filters=256, kernel_size=3, repetitions=3)\n        self.block_d = Block(filters=512, kernel_size=3, repetitions=3)\n        self.block_e = Block(filters=512, kernel_size=3, repetitions=3)\n\n        # Classification head\n        # Define a Flatten layer\n        self.flatten = tf.keras.layers.Flatten()\n        # Create a Dense layer with 256 units and ReLU as the activation function\n        self.fc = tf.keras.layers.Dense(256,activation='relu')\n        # Finally add the softmax classifier using a Dense layer\n        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n\n    def call(self, inputs):\n        # Chain all the layers one after the other\n        x = self.block_a(inputs)\n        x = self.block_b(x)\n        x = self.block_c(x)\n        x = self.block_d(x)\n        x = self.block_e(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:50:30.196553Z","iopub.execute_input":"2024-04-24T06:50:30.196912Z","iopub.status.idle":"2024-04-24T06:50:30.208512Z","shell.execute_reply.started":"2024-04-24T06:50:30.196879Z","shell.execute_reply":"2024-04-24T06:50:30.207740Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def get_model_accuracy(X_train, X_test, y_train, y_test):\n  vgg = MyVGG(num_classes=2)\n  vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n  vgg.fit(X_train,y_train,epochs=5)\n\n  # vgg.save_weights(\"models/vgg.weights.h5\")\n\n  y_pred=vgg.predict(X_test)\n\n  y_pred_binary=[]\n  for a in y_pred:\n    y_pred_binary.append(np.argmax(a))\n\n  y_pred_binary=np.array(y_pred_binary)\n\n  accuracy = metrics.accuracy_score(y_test,y_pred_binary)\n\n  print(\"Accuracy of model=\",accuracy)\n\n  print(classification_report(y_test, y_pred_binary, target_names=['0','1']))\n\n  return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:50:30.209882Z","iopub.execute_input":"2024-04-24T06:50:30.210263Z","iopub.status.idle":"2024-04-24T06:50:30.221764Z","shell.execute_reply.started":"2024-04-24T06:50:30.210231Z","shell.execute_reply":"2024-04-24T06:50:30.220835Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = get_train_and_test_data()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:50:30.223476Z","iopub.execute_input":"2024-04-24T06:50:30.223805Z","iopub.status.idle":"2024-04-24T06:59:50.652537Z","shell.execute_reply.started":"2024-04-24T06:50:30.223770Z","shell.execute_reply":"2024-04-24T06:59:50.651399Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Getting train and test data\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/skimage/transform/radon_transform.py:75: UserWarning: Radon transform: image must be zero outside the reconstruction circle\n  warn('Radon transform: image must be zero outside the '\n","output_type":"stream"}]},{"cell_type":"code","source":"get_model_accuracy(X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:59:50.654102Z","iopub.execute_input":"2024-04-24T06:59:50.654436Z","iopub.status.idle":"2024-04-24T07:00:40.015234Z","shell.execute_reply.started":"2024-04-24T06:59:50.654408Z","shell.execute_reply":"2024-04-24T07:00:40.014310Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - accuracy: 0.4922 - loss: 0.6935\nEpoch 2/5\n\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - accuracy: 0.4804 - loss: 0.6933\nEpoch 3/5\n\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - accuracy: 0.4883 - loss: 0.6932\nEpoch 4/5\n\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - accuracy: 0.5049 - loss: 0.6931\nEpoch 5/5\n\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - accuracy: 0.4843 - loss: 0.6932\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step\nAccuracy of model= 0.5016666666666667\n              precision    recall  f1-score   support\n\n           0       0.50      1.00      0.67       301\n           1       0.00      0.00      0.00       299\n\n    accuracy                           0.50       600\n   macro avg       0.25      0.50      0.33       600\nweighted avg       0.25      0.50      0.34       600\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"0.5016666666666667"},"metadata":{}}]}]}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzBu6o35D8Fv",
        "outputId": "672f0c05-378a-4fa1-e4ef-023450e9cdf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Poisson_Study/data_large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-TnX1o7CpOL",
        "outputId": "b69030e6-c48b-416b-b0af-923019d13441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 96s 621ms/step - loss: 1.3880 - accuracy: 0.5066 - val_loss: 0.6931 - val_accuracy: 0.5117\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a9fd815abc0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Poisson_Study/labels.csv\")\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "class Block(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
        "        super(Block, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.repetitions = repetitions\n",
        "        self.conv_layers = [\n",
        "            tf.keras.layers.Conv2D(filters, kernel_size, activation='relu', padding=\"same\")\n",
        "            for _ in range(repetitions)\n",
        "        ]\n",
        "        self.max_pool = tf.keras.layers.MaxPooling2D(pool_size, strides=strides)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for conv in self.conv_layers:\n",
        "            x = conv(x)\n",
        "        return self.max_pool(x)\n",
        "\n",
        "class MyVGG(tf.keras.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MyVGG, self).__init__()\n",
        "        self.block_a = Block(filters=64, kernel_size=3, repetitions=2)\n",
        "        self.block_b = Block(filters=128, kernel_size=3, repetitions=2)\n",
        "        self.block_c = Block(filters=256, kernel_size=3, repetitions=3)\n",
        "        self.block_d = Block(filters=512, kernel_size=3, repetitions=3)\n",
        "        self.block_e = Block(filters=512, kernel_size=3, repetitions=3)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc = tf.keras.layers.Dense(256, activation='relu')\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, return_last_conv=False):\n",
        "        x = self.block_a(inputs)\n",
        "        x = self.block_b(x)\n",
        "        x = self.block_c(x)\n",
        "        x = self.block_d(x)\n",
        "        x = self.block_e(x)  # Last convolutional output\n",
        "        if return_last_conv:\n",
        "            return x\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def call(self, inputs):\n",
        "        x = self.block_a(inputs)\n",
        "        x = self.block_b(x)\n",
        "        x = self.block_c(x)\n",
        "        x = self.block_d(x)\n",
        "        x = self.block_e(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def prepare_images(file_paths, image_size=(256, 256)):\n",
        "    img_array = []\n",
        "    labels = []\n",
        "    for file_path in file_paths:\n",
        "        base_name = os.path.basename(file_path)\n",
        "\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, image_size)\n",
        "            img = np.expand_dims(img, axis=-1)  # Add channel dimension for grayscale\n",
        "            img_array.append(img)\n",
        "\n",
        "            label_series = df[df['filename'] == base_name]['hemorrhage']\n",
        "            if not label_series.empty:\n",
        "                labels.append(label_series.iloc[0])\n",
        "            else:\n",
        "                print(f\"No label found for {base_name}; skipping image.\")\n",
        "                continue  # Skip this image if no label found\n",
        "        else:\n",
        "            print(\"Failed to load image:\", file_path)\n",
        "\n",
        "    return np.array(img_array) / 255.0, np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "file_paths = glob.glob(\"/content/drive/My Drive/Poisson_Study/data_large/*.png\")\n",
        "\n",
        "X, y = prepare_images(file_paths)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "\n",
        "model = MyVGG(num_classes=2)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=1, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/Poisson_Study/vgg.h5\")\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvyeKtcCeknH",
        "outputId": "1949d97c-8a70-48f1-c72d-1d68e0500a61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 3s 141ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_binary = [np.argmax(a) for a in y_pred]\n",
        "\n",
        "print(\"Accuracy of model = \", accuracy_score(y_test, y_pred_binary))\n",
        "print(classification_report(y_test, y_pred_binary, target_names=['0', '1']))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUl88forgald",
        "outputId": "8891fdbd-6dbf-48c1-cba5-b4a92f1b6368"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 2s 136ms/step\n",
            "Accuracy of model =  0.5116666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       293\n",
            "           1       0.51      1.00      0.68       307\n",
            "\n",
            "    accuracy                           0.51       600\n",
            "   macro avg       0.26      0.50      0.34       600\n",
            "weighted avg       0.26      0.51      0.35       600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}